---
title: "Forecasting the 2024 US Presidential Election"
author: 
  - Tianning He
  - Julia Lee
  - Shuangyuan Yang
thanks: "Code and data are available at: https://github.com/JuliaJLee/Forecasting_US_Election_2024.git"
date: today
date-format: long
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(tinytex)
library(knitr)
library(ggplot2)
library(dplyr)
library(arrow)
library(here)
```

# Introduction

*A paragraph for the broader context and motivation for the analysis + the gap that we want to address*

*A paragraph for that details what the analysis aims to do (i.e. its objective) + how*

*A paragraph for what was found and why findings are important (i.e. their implications)*

*A paragraph for setting up the rest of the paper*

# Data {#sec-data}

## Presidential General Election Polls Data

*A detailed description of the poll data (e.g. what the data shows, its variables, the date in which the data was downloaded + tables/graphs showing what the data looks like)*

To simulate, test, download, and clean the Presidential General Election Polls data, the statistical programming language R was used [@citeR]. Specific libraries that assisted the analysis include `tidyverse` [@tidyverse], `dplyr` [@dplyr],`tinytex` [@tinytex], `ggplot2` [@ggplot2], and `knitr` [@knitr]. 

(**pollster methodology and idealized methodology sections can be found in the Appendix - @sec-appendix**)

## Analysis Data 

*A detailed description of the clean poll data that was used within the analysis (e.g. what the data shows, why certain variables were chosen + tables/graphs showing what the data looks like)*

## An Account on Measurement

*A investigation into how voters' opinions or stances were translated into percentage of votes (i.e. a value) within the data*

# Model 

The objective of the present analysis is to forecast the percentage of support both presidential candidates, Kamala Harris and Donald Trump, will receive in the final week (October 27, 2024 to November 2, 2024) leading up to the election. The Presidential Poll data provided by 538 (CITE) reflects voters’ opinions and preferences about who should be the next President of the United States across time. As those opinions or preferences are subject to change as time goes on, this model seeks to account for this variability by building “seasonal indexes” and using them with a linear model to forecast the percentage of support for both presidential candidates.

In this model, a “season” is referred to as a 7-day week that is found between Sunday August 4, 2024 and Saturday October 26, 2024. The start date is August 4, 2024 because this date allows there to be enough data to observe the percentage of support for both candidates over several weeks. The end date is October 26, 2024 as this leaves roughly a week (October 27, 2024 to November 2, 2024) before the election on Tuesday November 5, 2024 to ensure that a forecast for this final week can be made. 

Further, this model considers the following variables: 

* **Pollsters with a numeric grade of 2.7 and above**: This model uses a cut-off of 2.7 for the numeric grade to strike a balance between the amount of data and the quality of the data. The design of this model requires that there is at least one poll that was conducted in each “season” or week, and this could not have been satisfied if only pollsters with a numeric grade of 3 are considered. A numeric grade of 2.7 and above allows this model to have sufficient data as well as data of high quality. 
* **The likely voter (lv) population**: Likely voters are defined as voters who show strong intentions to vote on election day (CITE). With this, the model focuses on this particular voter population to generate a forecast that more closely resembles election day.
* **States**: This model looks at polls that were state-specific rather than national polls. Though each state is not considered individually in this analysis, this model considers these state-specific polls as they also allow for sufficient data to be used within the model.
* **Sample Size**: Poll sample size is used within the model to pool the poll data for each week within the time period defined by the model above. 
* **Polls that did not ask about hypothetical match-ups**: As this model aims to forecast and compare support for the presidential candidates in the current 2024 election, hypothetical match-ups are not considered.
* **Presidential Candidates**: This model looks at the percentage of support for both Kamala Harris and Donald Trump throughout the analysis. 
* **Poll Start and End Dates**: Start and end dates are important variables in the model as they are used to categorize poll data into the different “seasons” or weeks between August 4, 2024 and October 26, 2024. 
* **Percentage of Support (pct)**: This is the target variable to be estimated by the model.  

## Model Process 

*Code that runs through the following steps can be found in the repository linked on page 1.*

### Step 1: Organize Poll Data for each Candidate by Week 

For this model, a total of 12 weeks of poll data is analyzed. The exact start and end dates of each week (defined by the model) can be found below in @tbl-weeks. Every four weeks corresponds to a month. The first four weeks are in August 2024, the next four weeks are in September 2024, and the last four weeks are in October 2024. 

```{r}
#| echo: false
#| message: false
#| label: tbl-weeks
#| tbl-cap: "Weeks Defined by the Model" 

values <- tibble(
  week_number = c(1:12), 
  week_dates = c("Aug. 4-10", "Aug. 11-17", "Aug. 18-24", "Aug. 25-31", "Sept. 1-7", "Sept. 8-14",
            "Sept. 15-21", "Sept. 22-28", "Sept. 29 - Oct. 5", "Oct. 6-12", "Oct. 13-19", "Oct. 20-26")
)

kable(values,
  col.names = c("Week", "Dates"),
    digits = 1,
    booktabs = TRUE,
    linesep = "",
    align = c("c", "c"),
    format.args = list(big.mark = ",")
  )

```


Using the start and end dates of the polls, the model first filters on the polls that were conducted between August 4, 2024 and October 26, 2024 for each candidate. Then, it assigns each poll to a week as outlined in @tbl-weeks. An example outcome is shown below for Kamala Harris (@tbl-organizingbyweek).

```{r}
#| echo: false
#| message: false
#| label: tbl-organizingbyweek
#| tbl-cap: "Poll Data Organized by Week For Harris" 

#### Organizing poll data by week ####

# Read in the cleaned analysis data

model_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))

#view(model_data)

# Change the format of both start and end dates

changed_dates <- model_data |>
  mutate(
    start_date = mdy(start_date),
    end_date = mdy(end_date)
  )

#view(changed_dates)

# Sort the data by end date in ascending order

sorted <- changed_dates[order(changed_dates$end_date),]

#view(sorted)

# Remove the polls from 2022 and 2023

only_2024 <- sorted[-c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14), ]

#view(only_2024)

# Keep polls that ended in Aug. 6 until Oct. 26, 2024

august_start <- only_2024[-(1:14),]

#view(august_start)

aug_to_oct <- august_start[-(481:630),]

#view(aug_to_oct)

# Remove pollster, numeric_grade, state, population, and hypothetical columns 
# and filter on HARRIS

columns_to_keep <- c("start_date", "end_date", "sample_size", "candidate_name", "pct")

simplified_data = aug_to_oct[columns_to_keep]

simplified_data_harris <- simplified_data |>
  filter(
    candidate_name == "Kamala Harris")

simplified_data_trump <- simplified_data |>
  filter(
    candidate_name == "Donald Trump")

#view(simplified_data_harris)

# Organize HARRIS data by week
## The following code (lines 99-101) was provided by a Stack Overflow answer 
## (link: https://stackoverflow.com/questions/40581705/group-dates-by-week-in-r)

harris_by_week <- simplified_data_harris %>% 
  mutate(week = cut.Date(end_date, breaks = "1 week", labels = FALSE)) %>% 
  arrange(end_date)

harris_by_week <- harris_by_week[,-c(1,2)]

#view(harris_by_week)

harris_by_week |>
  slice(1:6) |>
  kable(
    col.names = c("Sample Size", "Candidate", "Percentage of Support (pct)", "Week"),
    digits = 1,
    booktabs = TRUE,
    linesep = "",
    align = c("c", "c", "c", "c"),
    format.args = list(big.mark = ",")
  )

```


Each row in the outcome above (@tbl-organizingbyweek) represents a poll, and the “Week” column indicates the week in which that poll occurred. For example, the first four rows show polls that were conducted in the week of August 4 to 10, 2024. The last two rows show polls that occurred between August 11 to 17, 2024 (i.e. Week 2). Each poll’s sample size and pct estimate are also included.

### Step 2: Pool Poll Data by Week for both Candidates {#sec-step2}

With polls organized by week, the model now pools all the polls that occurred within a single week to generate a weighted average estimate of pct for that week. 

To pool the polls for each week, this model first creates a weight for each poll by: 

* (1) Finding the sum of the sample sizes of all polls in a given week 
* (2) Dividing each sample size of each poll within that week by the sum found in the previous step

An example of these two steps would be to find the sum of the first four sample sizes for week 1 in @tbl-organizingbyweek, and then divide 1000, 619, 661, and 693 from the first four rows of @tbl-organizingbyweek by the sum of the first four sample sizes.

Next, each weight for each poll within a given week is multiplied to the corresponding pct estimate. For example, by using @tbl-organizingbyweek, the model would multiply the quotient of (1000/sum of sample sizes) by 42.5, which is the pct estimate that corresponds to the poll with a sample size of 1000 in row 1 of @tbl-organizingbyweek. 

Lastly, by taking the sum of the products of each weight and the corresponding pct estimate, the model produces a weighted average pct estimate for each week. An example outcome is shown below for Kamala Harris (@tbl-weightforweek).

```{r}
#| echo: false
#| message: false
#| label: tbl-weightforweek
#| tbl-cap: "Weighted Average Percentage of Support for Harris By Week" 

# Pooling polls for HARRIS

pooled_polls_harris <- tibble(
  week_1 = round(sum(harris_by_week[1:4,]$pct * (harris_by_week[1:4,]$sample_size / 
                                                   sum(harris_by_week[1:4,]$sample_size))),2),
  week_2 = round(sum(harris_by_week[5:11,]$pct * (harris_by_week[5:11,]$sample_size / 
                                             sum(harris_by_week[5:11,]$sample_size))),2),
  week_3 = round(sum(harris_by_week[12,]$pct * (harris_by_week[12,]$sample_size / 
                                             sum(harris_by_week[12,]$sample_size))),2),
  week_4 = round(sum(harris_by_week[13:25,]$pct * (harris_by_week[13:25,]$sample_size / 
                                             sum(harris_by_week[13:25,]$sample_size))),2),
  week_5 = round(sum(harris_by_week[26:40,]$pct * (harris_by_week[26:40,]$sample_size / 
                                               sum(harris_by_week[26:40,]$sample_size))),2),
  week_6 = round(sum(harris_by_week[41:45,]$pct * (harris_by_week[41:45,]$sample_size / 
                                               sum(harris_by_week[41:45,]$sample_size))),2),
  week_7 = round(sum(harris_by_week[46:81,]$pct * (harris_by_week[46:81,]$sample_size / 
                                               sum(harris_by_week[46:81,]$sample_size))),2),
  week_8 = round(sum(harris_by_week[82:130,]$pct * (harris_by_week[82:130,]$sample_size / 
                                               sum(harris_by_week[82:130,]$sample_size))),2),
  week_9 = round(sum(harris_by_week[131:136,]$pct * (harris_by_week[131:136,]$sample_size / 
                                               sum(harris_by_week[131:136,]$sample_size))),2),
  week_10 = round(sum(harris_by_week[137:162,]$pct * (harris_by_week[137:162,]$sample_size / 
                                                sum(harris_by_week[137:162,]$sample_size))),2),
  week_11 = round(sum(harris_by_week[163:197,]$pct * (harris_by_week[163:197,]$sample_size / 
                                                sum(harris_by_week[163:197,]$sample_size))),2), 
  week_12 = round(sum(harris_by_week[198:240,]$pct * (harris_by_week[198:240,]$sample_size / 
                                                sum(harris_by_week[198:240,]$sample_size))),2)
)

#view(pooled_polls_harris)

## Flipping the dataframe to have week as one column and the weighted average pct 
## for each week in another column

## The following code (line 182) was provided by a Stack Overflow answer 
## (link: https://stackoverflow.com/questions/28680994/converting-rows-into-columns-and-columns-into-rows-using-r)

final_pooled_polls_harris <- as.data.frame(t(pooled_polls_harris))

#view(final_pooled_polls_harris)

#colnames(final_pooled_polls_harris)
#row.names(final_pooled_polls_harris)

## Renaming the weighted avg. pct column 

final_pooled_polls_harris <-
  final_pooled_polls_harris |>
  rename(
    "WeightedAveragepct" = V1)

## Adding another column for each week 

final_pooled_polls_harris$Week <- c(1:12)

## Bringing "Week" column to the front

final_pooled_polls_harris <- final_pooled_polls_harris %>% relocate(Week)

## Changing row names to just be numbers 1 through 12

rownames(final_pooled_polls_harris) <- c(1:12)

#view(final_pooled_polls_harris)

final_pooled_polls_harris |>
  slice(1:4) |>
  kable(
    col.names = c("Week", "Weighted Average Percentage of Support (pct)"),
    digits = 1,
    booktabs = TRUE,
    linesep = "",
    align = c("c", "c"),
    format.args = list(big.mark = ",")
  )

```

@tbl-weightforweek shows the average percentage of support that Harris received in the first four weeks. For instance, in Week 1 (i.e. during the week of August 4 to 10, 2024), Harris received an average support of 47.5% across the polls that occurred in within this time period.

### Step 3: Fit a Regression Model for Each Candidate using the Pooled Poll Data

Using the weighted average percentage of support (pct) for each week as the response variable, the model performs two regression analyses to predict the support for each candidate during each of the 12 weeks. The linear models are structured as follows: 

$$
\hat{y_i} = b_0 + b_1 \cdot w_i + \epsilon_i
$$
where

-   $\hat{y_i}$ represents the percentage of support (for Harris or Trump),

-   $b_0$ represents the intercept of the linear models,

-   $b_1$ represents the effect of each week,

-   $w_i$ represents the time period of a week (i = 1, 2,…, 12)

-   $\epsilon_i$ captures the error within the linear models

Summary outputs for each model (one for Harris and another for Trump) along with model diagnostics to validate these models can be found in the Appendix (SECTION). 

### Step 4: Find Seasonal (i.e. weekly) Indexes to Forecast Support for Harris and Trump

With the linear models fitted above, the model now creates a “seasonal” or weekly index for each week so that the week leading up to the election can be predicted while accounting for differences in voter opinions across different time periods. 

A seasonal index for each week is calculated by first computing the ratio, 
$$
 \frac{y}{\hat{y_i}}
$$. 

For each week, the model takes the weighted average percentage of support (pct) that was found in Step 2 (@sec-step2) and divides it by the predicted value that is found using the linear model. This produces an outcome like the following in @tbl-ratios. 

```{r}
#| echo: false
#| message: false
#| label: tbl-ratios
#| tbl-cap: "Ratios for Each Week"

# Regression model: HARRIS

harris_model <- lm(formula = WeightedAveragepct ~ Week, data = final_pooled_polls_harris)

pooled_and_predicted_harris <- final_pooled_polls_harris

pooled_and_predicted_harris$Predictedpct <- round(predict(harris_model), 2)

pooled_and_predicted_harris$Ratio <- round((pooled_and_predicted_harris$WeightedAveragepct / 
                                        pooled_and_predicted_harris$Predictedpct), 3)

#view(pooled_and_predicted_harris)

pooled_and_predicted_harris |>
  slice(1:4) |>
  kable(
    col.names = c("Week", "Weighted Average Percentage of Support (pct)", 
                  "Predicted Average Percent of Support (pct)", "Ratio"),
    digits = 3,
    booktabs = TRUE,
    linesep = "",
    align = c("c", "c", "c", "c"),
    format.args = list(big.mark = ",")
  )
```

Now, the since the data is manipulated such that every four weeks corresponds to a month (August, September, and October), it follows that the final week (October 27, 2024 to November 2, 2024) that this model aims to forecast is Week 13 and the first week of the next month, November. So, this model computes the average of the ratios for the first, second, third, and fourth weeks across each month to obtain a "seasonal" or weekly index that can be used to forecast Week 13. An example outcome is shown below @tbl-seasonal. 

```{r}
#| echo: false
#| message: false
#| label: tbl-seasonal
#| tbl-cap: "Seasonal (Weekly) Index for Each Week Across 3 Months"

## For HARRIS

ratios_harris <- tibble(
  Month = c("August 2024", "September 2024", "October 2024"),
  Week_1 = pooled_and_predicted_harris[c(1,5,9),]$Ratio,
  Week_2 = pooled_and_predicted_harris[c(2,6,10),]$Ratio,
  Week_3 = pooled_and_predicted_harris[c(3,7,11),]$Ratio,
  Week_4 = pooled_and_predicted_harris[c(4,8,12),]$Ratio
)

#view(ratios_harris)

seasonal_index_harris <- tibble(
  Week_1_Index = round(((sum(pooled_and_predicted_harris[c(1,5,9),]$Ratio)) / 3), 3),
  Week_2_Index = round(((sum(pooled_and_predicted_harris[c(2,6,10),]$Ratio)) / 3), 3),
  Week_3_Index = round(((sum(pooled_and_predicted_harris[c(3,7,11),]$Ratio)) / 3), 3),
  Week_4_Index = round(((sum(pooled_and_predicted_harris[c(4,8,12),]$Ratio)) / 3), 3),
)

#view(seasonal_index_harris)

seasonal_index_harris |>
  kable(
    col.names = c("Week 1", "Week 2", "Week 3", "Week 4"),
    digits = 3,
    booktabs = TRUE,
    linesep = "",
    align = c("c", "c", "c", "c"),
    format.args = list(big.mark = ",")
  )
```

Using the seasonal index for Week 1 (0.993) presented in @tbl-seasonal, this model can forecast the percentage of support that Harris will receive in Week 13 by:

* (1) Plugging in $w$ = 13 to the linear model for Harris to predict her percentage of support
* (2) Multiplying the predicted value from the linear model by the seasonal index

The example outcomes provided throughout this section are for Kamala Harris only. It is important to note that the same process is also repeated for Donald Trump within the model.

## Evaluating the Model

By pooling the polls for each of the defined weeks, the model assumes that the polls are unbiased – which is often not the case. While pooling polls that have occurred in a similar time period provides more precision than a single poll, a limitation of this model is that it overlooks the potential biases that can exist within the polls. Biases within polls can arise from their methodology, their audience, and the location in which the poll was conducted. As these variables are not explicitly considered by the model, it would not be appropriate to apply this model to forecast percentage of support as a function of different methodologies, voter populations, or states. 

Despite these limitations, this model’s strength lies in its ability to account for variations across time. This approach of using seasonal indexes and regression to forecast the percentage of support (pct) for both presidential candidates is able to capture seasonal (i.e. weekly) variation within the percentage of support candidates received and assess long-term trends. As such, this model can provide both a numerical outcome (i.e. a forecasted percentage of support) for each candidate along with a means to observe how the percentage of support for the presidential candidates has changed over time. As these strengths align with the objective of the analysis to forecast the percentage of support the presidential candidates will receive in the final week (October 27, 2024 to November 2, 2024) leading up to the election, this model is employed to obtain the findings presented in the next section (@sec-results). 

# Results {#sec-results}

## Change in the Percentage of Support (pct) for Both Presidential Candidates Over Time 

This initial analysis aims to understand how the percentage of support for both candidates has changed over the course of the 12 weeks defined by the model.

```{r}
#| echo: false 
#| message: false
#| label: fig-pctovertime
#| fig-cap: Percentage of Support for Both Candidates Over 12 Weeks (August 4 to October 26, 2024)

# For TRUMP

# Organize TRUMP data by week
## The following code (lines 111-113) was provided by a Stack Overflow answer 
## (link: https://stackoverflow.com/questions/40581705/group-dates-by-week-in-r)

trump_by_week <- simplified_data_trump %>% 
  mutate(week = cut.Date(end_date, breaks = "1 week", labels = FALSE)) %>% 
  arrange(end_date)

trump_by_week <- trump_by_week[,-c(1,2)]

#view(trump_by_week)

# Pooling polls for TRUMP

pooled_polls_trump <- tibble(
  week_1 = round(sum(trump_by_week[1:4,]$pct * (trump_by_week[1:4,]$sample_size / 
                                                   sum(trump_by_week[1:4,]$sample_size))),2),
  week_2 = round(sum(trump_by_week[5:11,]$pct * (trump_by_week[5:11,]$sample_size / 
                                                    sum(trump_by_week[5:11,]$sample_size))),2),
  week_3 = round(sum(trump_by_week[12,]$pct * (trump_by_week[12,]$sample_size / 
                                                  sum(trump_by_week[12,]$sample_size))),2),
  week_4 = round(sum(trump_by_week[13:25,]$pct * (trump_by_week[13:25,]$sample_size / 
                                                     sum(trump_by_week[13:25,]$sample_size))),2),
  week_5 = round(sum(trump_by_week[26:40,]$pct * (trump_by_week[26:40,]$sample_size / 
                                                     sum(trump_by_week[26:40,]$sample_size))),2),
  week_6 = round(sum(trump_by_week[41:45,]$pct * (trump_by_week[41:45,]$sample_size / 
                                                     sum(trump_by_week[41:45,]$sample_size))),2),
  week_7 = round(sum(trump_by_week[46:81,]$pct * (trump_by_week[46:81,]$sample_size / 
                                                     sum(trump_by_week[46:81,]$sample_size))),2),
  week_8 = round(sum(trump_by_week[82:130,]$pct * (trump_by_week[82:130,]$sample_size / 
                                                      sum(trump_by_week[82:130,]$sample_size))),2),
  week_9 = round(sum(trump_by_week[131:136,]$pct * (trump_by_week[131:136,]$sample_size / 
                                                       sum(trump_by_week[131:136,]$sample_size))),2),
  week_10 = round(sum(trump_by_week[137:162,]$pct * (trump_by_week[137:162,]$sample_size / 
                                                        sum(trump_by_week[137:162,]$sample_size))),2),
  week_11 = round(sum(trump_by_week[163:197,]$pct * (trump_by_week[163:197,]$sample_size / 
                                                        sum(trump_by_week[163:197,]$sample_size))),2), 
  week_12 = round(sum(trump_by_week[198:240,]$pct * (trump_by_week[198:240,]$sample_size / 
                                                        sum(trump_by_week[198:240,]$sample_size))),2)
)

#view(pooled_polls_trump)

## Flipping the dataframe to have week as one column and the weighted average pct 
## for each week in another column

## The following code (line 182) was provided by a Stack Overflow answer 
## (link: https://stackoverflow.com/questions/28680994/converting-rows-into-columns-and-columns-into-rows-using-r)

final_pooled_polls_trump <- as.data.frame(t(pooled_polls_trump))

#view(final_pooled_polls_trump)

#colnames(final_pooled_polls_trump)
#row.names(final_pooled_polls_trump)

## Renaming the weighted avg. pct column 

final_pooled_polls_trump <-
  final_pooled_polls_trump |>
  rename(
    "WeightedAveragepct" = V1)

## Adding another column for each week 

final_pooled_polls_trump$Week <- c(1:12)

## Bringing "Week" column to the front

final_pooled_polls_trump <- final_pooled_polls_trump %>% relocate(Week)

## Changing row names to just be numbers 1 through 12

rownames(final_pooled_polls_trump) <- c(1:12)

#view(final_pooled_polls_trump)

final_pooled_both <- merge(final_pooled_polls_harris, final_pooled_polls_trump, 
                           by="Week")

names(final_pooled_both)[2] <- "Harris"

names(final_pooled_both)[3] <- "Trump"

#view(final_pooled_both)

ggplot(data = final_pooled_both, aes(x = Week)) + 
  geom_line(aes(y = Harris, colour = "Harris")) + 
  geom_line(aes(y = Trump, colour = "Trump")) +
  geom_point(aes(y = Harris), color = "blue") +
  geom_point(aes(y = Trump), color="red") +
  theme_light() +
  labs(
    y = "Percentage of Support (%)",
    caption = "Data Source: 538"
  ) + 
  ylim(40,55) + scale_x_continuous(name = "Week", breaks = seq(1,12,by=1), limits = c(1, 12)) + 
  ggtitle("Percentage of Support For Presidential Candidates Over Time") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(name = "Candidate", values = c("Harris" = "blue", "Trump" = "red"))

```

@fig-pctovertime presents the weighted average percentage of support for each presidential candidate over time. While both candidates appear to have had fluctuations in the percentage of support they received, the difference between their percentage of support is smaller in Week 12 than it was at Week 1. In week 1, Trump received an additional 2.39% of support compared to Harris, and in Week 12, his percentage of support was 1.35% higher than Harris'. This pattern further indicates that as support for Trump has dropped, support for Harris has increased over the course of 12 weeks.

## Predicting the Percentage of Support (pct) for Both Presidential Candidates Over Time

```{r}
#| echo: false 
#| message: false
#| label: fig-predictedharris
#| fig-cap: Predicted Percentage of Support for Harris Over 12 Weeks (August 4 to October 26, 2024)

# Regression model: HARRIS

harris_model <- lm(formula = WeightedAveragepct ~ Week, data = final_pooled_polls_harris)

# Adding predicted values for weeks 1 to 12 using the linear model as a new column next to the weighted 
# average pct

pooled_and_predicted_harris <- final_pooled_polls_harris

pooled_and_predicted_harris$Predictedpct <- round(predict(harris_model), 2)

#view(pooled_and_predicted_harris)

ggplot(pooled_and_predicted_harris, aes(Week, Predictedpct)) +
  geom_point(colour = "blue") +
  geom_smooth(method='lm', color='black') +
  theme_light() +
  labs(x = "Week", y = "Percentage of Support (pct)", 
       title = "Predicted Percentage of Support (pct) for Harris Over Time") +
  theme(plot.title = element_text(hjust=0.5)) +
  scale_x_continuous(name = "Week", breaks = seq(1,12,by=1), limits = c(1, 12)) +
  geom_line(aes(y = WeightedAveragepct, colour = "Weighted Average pct")) +
  scale_color_manual(name = "Data", values = c("Weighted Average pct" = "darkgreen"))
  
```


```{r}
#| echo: false 
#| message: false
#| label: fig-predictedtrump
#| fig-cap: Predicted Percentage of Support for Trump Over 12 Weeks (August 4 to October 26, 2024)

# Regression model: TRUMP

trump_model <- lm(formula = WeightedAveragepct ~ Week, data = final_pooled_polls_trump)

# Adding predicted values for weeks 1 to 12 using the linear model as a new column next to the weighted 
# average pct

pooled_and_predicted_trump <- final_pooled_polls_trump

pooled_and_predicted_trump$Predictedpct <- round(predict(trump_model), 2)

#view(pooled_and_predicted_trump)

ggplot(pooled_and_predicted_trump, aes(Week, Predictedpct)) +
  geom_point(colour = "red") +
  geom_smooth(method='lm', color='black') +
  theme_light() +
  labs(x = "Week", y = "Percentage of Support (pct)", 
       title = "Predicted Percentage of Support (pct) for Trump Over Time") +
  theme(plot.title = element_text(hjust=0.5)) +
  scale_x_continuous(name = "Week", breaks = seq(1,12,by=1), limits = c(1, 12)) +
  geom_line(aes(y = WeightedAveragepct, colour = "Weighted Average pct")) +
  scale_color_manual(name = "Data", values = c("Weighted Average pct" = "darkgreen"))

```

@fig-predictedharris and @fig-predictedtrump provides a comparison of the predicted percentage of support from the linear model and the weighted average percentage of support that was computed with the poll data for Harris and Trump. Though both models do not seem to accurately capture the fluctuations in support each candidate received over time, they do appear to capture the overall increase in support for Harris along with the overall decrease in support for Trump over the 12 weeks. This further gives rise to the idea that while the percentage of support for Trump decreased, the percentage of support for Harris increased as the weeks went by. 

## Forecasting the Percentage of Support (pct) for Both Presidential Candidates For Week 13

The main objective of this model is to forecast the percentage of support Harris and Trump will receive in the final week before the election. This week - October 27, 2024 to November 2, 2024 - is Week 13, and the model uses a seasonal index along with a predicted value from the linear model to compute a forecast. The forecasted percentages of support for each candidate are shown in @fig-forecast below. 

```{r}
#| echo: false 
#| message: false
#| warning: false
#| label: fig-forecast
#| fig-cap: Presenting the Forecasted Percentages of Support for Harris and Trump in Week 13

# Adding a column for a ratio for each week


## For HARRIS 

pooled_and_predicted_harris <- final_pooled_polls_harris

pooled_and_predicted_harris$Predictedpct <- round(predict(harris_model), 2)

pooled_and_predicted_harris$Ratio <- round((pooled_and_predicted_harris$WeightedAveragepct / 
                                        pooled_and_predicted_harris$Predictedpct), 3)

#view(pooled_and_predicted_harris)


## For TRUMP 

pooled_and_predicted_trump <- final_pooled_polls_trump

pooled_and_predicted_trump$Predictedpct <- round(predict(trump_model), 2)

pooled_and_predicted_trump$Ratio <- round((pooled_and_predicted_trump$WeightedAveragepct / 
                                              pooled_and_predicted_trump$Predictedpct), 3)

#view(pooled_and_predicted_trump)

# Now since the data was manipulated so that every four weeks corresponds to a month (August, 
# September, and October), and as week 13 is the first week of November in the model, need to 
# find the seasonal index (i.e. average ratio) for the first week across each month to be able 
# to forecast it


## For HARRIS

ratios_harris <- tibble(
  Month = c("August 2024", "September 2024", "October 2024"),
  Week_1 = pooled_and_predicted_harris[c(1,5,9),]$Ratio,
  Week_2 = pooled_and_predicted_harris[c(2,6,10),]$Ratio,
  Week_3 = pooled_and_predicted_harris[c(3,7,11),]$Ratio,
  Week_4 = pooled_and_predicted_harris[c(4,8,12),]$Ratio
)

#view(ratios_harris)

seasonal_index_harris <- tibble(
  Week_1_Index = round(((sum(pooled_and_predicted_harris[c(1,5,9),]$Ratio)) / 3), 3),
  Week_2_Index = round(((sum(pooled_and_predicted_harris[c(2,6,10),]$Ratio)) / 3), 3),
  Week_3_Index = round(((sum(pooled_and_predicted_harris[c(3,7,11),]$Ratio)) / 3), 3),
  Week_4_Index = round(((sum(pooled_and_predicted_harris[c(4,8,12),]$Ratio)) / 3), 3),
)

#view(seasonal_index_harris)


## For TRUMP

ratios_trump <- tibble(
  Month = c("August 2024", "September 2024", "October 2024"),
  Week_1 = pooled_and_predicted_trump[c(1,5,9),]$Ratio,
  Week_2 = pooled_and_predicted_trump[c(2,6,10),]$Ratio,
  Week_3 = pooled_and_predicted_trump[c(3,7,11),]$Ratio,
  Week_4 = pooled_and_predicted_trump[c(4,8,12),]$Ratio
)

#view(ratios_trump)

seasonal_index_trump <- tibble(
  Week_1_Index = round(((sum(pooled_and_predicted_trump[c(1,5,9),]$Ratio)) / 3), 3),
  Week_2_Index = round(((sum(pooled_and_predicted_trump[c(2,6,10),]$Ratio)) / 3), 3),
  Week_3_Index = round(((sum(pooled_and_predicted_trump[c(3,7,11),]$Ratio)) / 3), 3),
  Week_4_Index = round(((sum(pooled_and_predicted_trump[c(4,8,12),]$Ratio)) / 3), 3),
)

#view(seasonal_index_trump)

#### Forecasting Harris and Trump support in week 13 ####

# Now can use linear model and index to forecast the percentage of support each candidate 
# will have in week 13 (i.e. the week leading up to the election)

## For HARRIS

### Predicting pct for week 13 using linear model

new_point = data.frame(Week = 13)

prediction = predict(harris_model, newdata = new_point)

#prediction

### Multiplying the predicted value by the seasonal index for week 1
### Get the seasonal index for week 1

forecasted_pct = prediction * (seasonal_index_harris[1,1])

#forecasted_pct

#### Therefore, forecast that the percentage of support for Harris in the week leading up to 
#### the election will be 48.03%.


## For TRUMP

### Predicting pct for week 13 using linear model

new_point = data.frame(Week = 13)

prediction = predict(trump_model, newdata = new_point)

#prediction

### Multiplying the predicted value by the seasonal index for week 1
### Get the seasonal index for week 1

forecasted_pct = prediction * (seasonal_index_trump[1,1])

#forecasted_pct

#### Therefore, forecast that the percentage of support for Trump in the week leading up to 
#### the election will be 47.98%.

ggplot(data = final_pooled_both, aes(x = Week)) + 
  geom_line(aes(y = Harris, colour = "Harris")) + 
  geom_line(aes(y = Trump, colour = "Trump")) +
  geom_point(aes(y = Harris), color = "blue") +
  geom_point(aes(y = Trump), color="red") +
  theme_light() +
  labs(
    y = "Percentage of Support (%)",
    caption = "Data Source: 538"
  ) + 
  ylim(46,50) + scale_x_continuous(name = "Week", breaks = seq(1,13,by=1), limits = c(1, 13)) + 
  ggtitle("Forecasted Percentages of Support for Harris and Trump in Week 13") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(name = "Candidate", values = c("Harris" = "blue", "Trump" = "red")) +
  geom_point(aes(x = 13, y = 48.03), colour = "blue", size = 1.5) + 
  geom_point(aes(x = 13, y = 47.98), colour = "red", size = 1.5) 

```

With @fig-forecast, it appears as the presidential election will be a tight race as the forecasts of percentage of support for Harris and Trump in Week 13 are very similar. In the final week leading up to the election (October 27, 2024 to November 2, 2024), Harris is expected to receive more support while Trump is expected to receive less support in Week 13. The exact forecasts of the model are as follows:

* This model forecasts that the percentage of support for Harris in the week leading up to the election will be 48.03%.
* On the other hand, the model forecasts that the percentage of support for Trump in the week leading up to the election will be 47.98%.

\newpage


# Discussion {#sec-discussion}

## Summary

*A paragraph that summarizes what was done in the analysis and a brief overview of the main findings*

## Implications

*A paragraph about what the main findings imply about the election - why they are relevant*

## Limitations

*A paragraph about the limitations of the model - shortcomings due to the decisions that were made in the model*

## Future Directions

*A paragraph about what can be done in the future*

\newpage

\appendix

# Appendix {#sec-appendix}

## Pollster Methodology 

We selected YouGov, a polling organization, and discussed its survey methodology and its main features, strengths, and weaknesses. From the data obtained, the population of YouGov surveys is American voters, especially citizens who are eligible to vote. YouGov's framework is usually participants who voluntarily register and participate in surveys regularly. These panel members express their opinions in the form of online questionnaires. The sample is a part of YouGov's online panel. In the data, we see some specific stratification information, such as political parties (DEM, REP, etc.), which indicates that YouGov may use stratified sampling to ensure the diversity of the sample.
YouGov's sample is recruited through a voluntary online panel. Users can actively register to become panel members and accept survey invitations at any time. This recruitment method is non-random, but the cost is relatively low and the number of people is large.

YouGov uses stratified sampling, which stratifies respondents according to demographic variables, such as age, gender, political party, etc., to ensure that each subgroup in the sample is fully represented. Stratified sampling can ensure that different groups (such as party supporters, different age groups, etc.) are properly represented, avoid a single group dominating, improve estimation accuracy, and reduce sampling errors. However, if the stratification criteria are not properly chosen or there are large individual differences within the strata, stratified sampling may increase sampling errors. It may be more time-consuming to design and implement than simple random sampling, and more resources are required to determine the stratification and sampling scheme, especially when the population size is large.

YouGov uses weighting to adjust when dealing with non-response issues. When some people do not respond or the response rate of certain groups is low, YouGov will weight the responses of these groups according to demographic data to ensure that the final survey results can more accurately reflect the overall situation. This can help correct the bias caused by the low response rate of certain groups and make the results more representative.
YouGov's questionnaire is answered online, which can quickly obtain a large amount of data, and the population (people who answer the questionnaire) is distributed in various places, which improves flexibility and efficiency. The questionnaire also covers a variety of candidates and political parties, and distinguishes the support rates of different political parties. The content of the questionnaire can be changed according to different groups to ensure that the survey questions are relevant to the background of the respondents. At the same time, there are some potential problems with the questionnaire. First, since the questionnaire is answered online, some people may not answer the questionnaire seriously, which may affect the accuracy of the questionnaire. Secondly, since it is voluntary to participate in the questionnaire, some groups may be under-represented or over-represented, which will also lead to biased survey results.

## Idealized Pollster Methodology

Survey Form Link: https://forms.gle/S4cyiZNej46zfxq29

### Introduction
In this appendix, I present a detailed survey methodology designed to predict the outcome of the upcoming U.S. presidential election. The design leverages a $100K budget and focuses on achieving a representative, accurate, and methodologically robust sample. The survey will use mixed-mode recruitment (in person, phone, online, and SMS), with a sample size of 3,000 respondents. Detailed weighting adjustments and validation strategies will ensure the integrity of the data, while aggregation with other polls will provide a more accurate forecast.

### Sampling Approach
#### Target Population
The survey targets the U.S. voting-age population, defined as U.S. citizens aged 18 and older. The target population includes both already voted voters and those who plan to vote.

#### Sample Size and Confidence
As for sample size, a total of 3,000 respondents will be surveyed. This provides a margin of error of ±2% at a 95% confidence level, ensuring reliable predictions at the national level. 
As for the confidence, the larger the sample size, the smaller the margin of error. Given the $100K budget, this is an optimal balance between cost and statistical reliability.

#### Stratified Sampling Approach
To ensure representatives, the sample will be stratified across key demographic factors like their age group, gender, race, education level, job type, income level, house situation, political party, living state and so on. Specifically, for those Swing states (such as Nevada, Arizona, Wisconsin, Michigan, Pennsylvania, North Carolina, and Georgia) will be over-sampled to ensure an accurate prediction in these battleground regions, where small shifts in voter behavior can heavily influence the election outcome. For example, instead of targeting only 8% of the sample in swing states (proportional to the population), we might over-sample to 20%.

#### Bias
Firstly, relying too much on online survey may skew results towards who are younger and more internet-savvy respondents. To solve this, a portion of the budget will be dedicated to reaching older and rural voters via phone surveys and in person survey. Besides, We will solve non-response bias by offering incentives. 

### Recruitment Strategy
#### Mixed-Mode Recruitment
The recruitment strategy uses a mix of recruitment channels to ensure diverse participation across demographic groups.

1. Phone Recruitment (Random Digit Dialing - RDD) or in person survey:
Budget: $30,000
Goal: Target older voters, particularly those 65+ and rural populations, who are less likely to respond to online surveys.
Method: RDD will include both land-lines and mobile numbers to maximize reach, especially among older voters.
Response Rate: Assuming a 10-15% response rate, we expect to recruit around 1,000 respondents via phone interviews.

2. Online Panel Recruitment:
Budget: $40,000
Goal: Capture younger, more tech-savvy respondents (ages 18-44) and urban populations who are more likely to participate in online surveys.
Method: Use reputable online panels such as YouGov or Ipsos. These panels provide access to a large pool of respondents pre-screened for voter eligibility.
Response Rate: With a budget of $20,000, we expect to recruit about 1,500 respondents from these panels.

3. Text-to-Web Invitations (SMS Surveys):
Budget: $15,000
Goal: Reach respondents through mobile-friendly surveys, targeting younger voters (18-34) and those who prefer mobile interaction.
Method: Send SMS invitations with a link to the online survey (via Google Forms), targeting respondents in both urban and rural areas.
Response Rate: We expect to recruit 500 respondents via SMS links.

#### Incentives for Participation
To improve response rates, we will offer $5 digital gift cards as an incentive to complete the survey.
Budget: $15,000 for approximately 3,000 respondents.
This will particularly help increase participation among hard-to-reach groups, such as low-income individuals and rural populations.

### Data Validation
#### Weighting Adjustments
Post-stratification weighting will be used to adjust the sample to reflect the actual U.S. voting population. This ensures that underrepresented groups (e.g., younger voters, minorities) are appropriately represented in the final analysis. Weights will be calculated based on age, race, gender, education, and some other factors by using Census data as a benchmark.

#### Screening Questions
The survey will include key screening questions to ensure eligibility:

"Are you a U.S. citizen eligible to vote in the ongoing U.S. presidential election?"
"Are you at least 18 years old, making you eligible to vote in the ongoing U.S. presidential election?"
"Have you already voted in the 2024 U.S. presidential election?"
Respondents who do not meet these criteria will be excluded from the analysis.

#### Fraud Detection
To ensure high-quality responses:

1. Consistency Checks: Use validation questions to ensure the consistency of answers. For example, responses on party affiliation and voting intention will be cross-checked to identify inconsistencies.
2. Re-contacting: Randomly re-contact a subset of respondents to verify their initial responses.

\newpage


# References